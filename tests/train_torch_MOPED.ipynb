{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "em2aVoafL-ML"
   },
   "source": [
    "# Para ejecutar en Google Colab en Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1626216648545,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "qJhAwN4z7jJ9",
    "outputId": "4bddcff6-8536-41d9-d105-2dbc23fecaf6"
   },
   "outputs": [],
   "source": [
    "# Montamos el Drive al Notebook\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1626216650801,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "pnCMtpvc7n1s",
    "outputId": "79a7a3a2-6c71-4c17-c89f-85e98bc28297"
   },
   "outputs": [],
   "source": [
    "# Verificamos el directorio en el que nos encontramos\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1626216652277,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "OoAkWfZL7oCL",
    "outputId": "a6b806df-70b5-41ed-b70f-7393858de298"
   },
   "outputs": [],
   "source": [
    "# Cambiamos de directorio al Drive\n",
    "import os\n",
    "os.chdir(\"drive/My Drive/PruebasCOLAB3/OF-PathPred/tests\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYovpqgdMNjU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GM2YmtlMTXp"
   },
   "source": [
    "# Inicio de CÃ³digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5361,
     "status": "ok",
     "timestamp": 1626216661406,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "2hOKb3HV6YKm"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import sys,os,logging\n",
    "''' TF_CPP_MIN_LOG_LEVEL\n",
    "0 = all messages are logged (default behavior)\n",
    "1 = INFO messages are not printed\n",
    "2 = INFO and WARNING messages are not printeds\n",
    "3 = INFO, WARNING, and ERROR messages are not printed\n",
    "'''\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "sys.path.append('../bayesian-torch')\n",
    "sys.path.append('../OF-PathPred')\n",
    "sys.path.append('..')\n",
    "\n",
    "import math,numpy as np\n",
    "# Important imports\n",
    "import matplotlib.pyplot as plt\n",
    "from path_prediction.datasets_utils import setup_loo_experiment\n",
    "from path_prediction.testing_utils import evaluation_minadefde,evaluation_qualitative,evaluation_attention,plot_comparisons_minadefde, get_testing_batch\n",
    "from path_prediction.training_utils import Experiment_Parameters\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(1)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from bayesian_torch.layers import LinearReparameterization\n",
    "from bayesian_torch.layers import LSTMReparameterization\n",
    "\n",
    "# Local models\n",
    "from models.lstm_encdec_variational import lstm_encdec_variational\n",
    "from utils.datasets_utils import traj_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: NVIDIA GeForce GTX 1060\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[5]:\n",
    "logging.basicConfig(format='%(levelname)s: %(message)s',level=20)\n",
    "# GPU\n",
    "if torch.cuda.is_available():\n",
    "    logging.info(torch.cuda.get_device_name(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1626216675247,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "oYyijVou6YKq"
   },
   "outputs": [],
   "source": [
    "# Load the default parameters\n",
    "experiment_parameters = Experiment_Parameters(add_kp=False,obstacles=False)\n",
    "\n",
    "dataset_dir   = \"../OF-PathPred/datasets/\"\n",
    "dataset_names = ['eth-hotel','eth-univ','ucy-zara01','ucy-zara02','ucy-univ']\n",
    "#dataset_names = ['eth-hotel','eth-univ','ucy-zara01']\n",
    "idTest        = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54443,
     "status": "ok",
     "timestamp": 1626216963560,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "bySxfWOc6YKs",
    "outputId": "5529c0c1-2034-4030-9dbd-d6bf5fa79019"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Testing/validation dataset: ['ucy-zara01']\n",
      "INFO: Training datasets: ['eth-hotel', 'eth-univ', 'ucy-zara02', 'ucy-univ']\n",
      "INFO: Extracting data from the datasets\n",
      "INFO: Sequence length (observation+prediction): 20\n",
      "INFO: Reading ../OF-PathPred/datasets/ucy-zara01/mundo/mun_pos.csv\n",
      "INFO: Total number of frames: 872\n",
      "INFO: Total number of trajectories in this dataset: \n",
      "INFO: Add social interaction data (optical flow)\n",
      "INFO: Total number of sample sequences: \n",
      "INFO: Sequence length (observation+prediction): 20\n",
      "INFO: Reading ../OF-PathPred/datasets/eth-hotel/mundo/mun_pos.csv\n",
      "INFO: Total number of frames: 1168\n",
      "INFO: Total number of trajectories in this dataset: \n",
      "INFO: Add social interaction data (optical flow)\n",
      "INFO: Reading ../OF-PathPred/datasets/eth-univ/mundo/mun_pos.csv\n",
      "INFO: Total number of frames: 876\n",
      "INFO: Total number of trajectories in this dataset: \n",
      "INFO: Add social interaction data (optical flow)\n",
      "INFO: Reading ../OF-PathPred/datasets/ucy-zara02/mundo/mun_pos.csv\n",
      "INFO: Total number of frames: 1052\n",
      "INFO: Total number of trajectories in this dataset: \n",
      "INFO: Add social interaction data (optical flow)\n",
      "INFO: Reading ../OF-PathPred/datasets/ucy-univ/mundo/mun_pos.csv\n",
      "INFO: Total number of frames: 541\n",
      "INFO: Total number of trajectories in this dataset: \n",
      "INFO: Add social interaction data (optical flow)\n",
      "INFO: Total number of sample sequences: \n",
      "INFO: Training data: 15481\n",
      "INFO: Test data: 2356\n",
      "INFO: Validation data: 1720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_traj:  (15481, 8, 2)\n",
      "obs_traj_rel:  (15481, 8, 2)\n",
      "obs_traj_theta:  (15481, 8, 1)\n",
      "pred_traj:  (15481, 12, 2)\n",
      "pred_traj_rel:  (15481, 12, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and perform the split\n",
    "training_data, validation_data, test_data, test_homography = setup_loo_experiment('ETH_UCY',dataset_dir,dataset_names,2,experiment_parameters,use_pickled_data=False,pickle_dir=\"../pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1626217018285,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "00GpCrbg6YKt"
   },
   "outputs": [],
   "source": [
    "num_epochs     = 2\n",
    "initial_lr     = 0.03\n",
    "batch_size     = 256\n",
    "num_mc         = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1626217038070,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "jnCdyKzuW_gI"
   },
   "outputs": [],
   "source": [
    "# Creamos el dataset para torch\n",
    "train_data = traj_dataset(training_data['obs_traj_rel'], training_data['pred_traj_rel'],training_data['obs_traj'], training_data['pred_traj'])\n",
    "val_data = traj_dataset(validation_data['obs_traj_rel'], validation_data['pred_traj_rel'],validation_data['obs_traj'], validation_data['pred_traj'])\n",
    "test_data = traj_dataset(test_data['obs_traj_rel'], test_data['pred_traj_rel'], test_data['obs_traj'], test_data['pred_traj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1626217045689,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "5j23o7zkGh1A"
   },
   "outputs": [],
   "source": [
    "# Form batches\n",
    "batched_train_data = torch.utils.data.DataLoader( train_data, batch_size = batch_size, shuffle=True)\n",
    "batched_val_data =  torch.utils.data.DataLoader( val_data, batch_size = batch_size, shuffle=True)\n",
    "batched_test_data =  torch.utils.data.DataLoader( test_data, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1285,
     "status": "ok",
     "timestamp": 1626217050435,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "IRwsEyE2emM4"
   },
   "outputs": [],
   "source": [
    "prior_mu = 0.0\n",
    "prior_sigma = 1.0\n",
    "posterior_mu_init = 0.0\n",
    "posterior_rho_init = -4.0\n",
    "posterior_rho_init = -3.0 # 0.006715348489117967 # 0.01814992791780978 # 0.04858735157374196\n",
    "\n",
    "len_trainset = 15481\n",
    "len_valset = 1720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_determinista(nn.Module):\n",
    "    def __init__(self, in_size, embedding_dim, hidden_dim, output_size):\n",
    "        super(LSTM_determinista, self).__init__()\n",
    "\n",
    "        # Layers\n",
    "        self.embedding = nn.Linear(in_size, embedding_dim)\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.decoder = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "        #self.loss_fun = nn.CrossEntropyLoss()\n",
    "        self.loss_fun = nn.MSELoss()\n",
    "\n",
    "    def forward(self, X, y, training=False):\n",
    "\n",
    "        # Copy data\n",
    "        x = X\n",
    "        # Last position traj\n",
    "        x_last = X[:,-1,:].view(len(x), 1, -1) \n",
    "\n",
    "        # Layers\n",
    "        emb = self.embedding(X) # encoder for batch\n",
    "        lstm_out, (hn1, cn1) = self.lstm1(emb.permute(1,0,2)) # LSTM for batch [seq_len, batch, input_size] \n",
    "\n",
    "        loss = 0\n",
    "        pred = []\n",
    "        for i, target in enumerate(y.permute(1,0,2)):\n",
    "            emb_last = self.embedding(x_last) # encoder for last position\n",
    "            lstm_out, (hn2, cn2) = self.lstm2(emb_last.permute(1,0,2), (hn1,cn1)) # lstm for last position with hidden states from batch\n",
    "\n",
    "            # Decoder and Prediction\n",
    "            dec = self.decoder(hn2.permute(1,0,2))\n",
    "            t_pred = dec + x_last\n",
    "            pred.append(t_pred)\n",
    "\n",
    "            # Calculate of loss\n",
    "            loss += self.loss_fun(t_pred, target.view(len(target), 1, -1))\n",
    "\n",
    "            # Update the last position\n",
    "            if training:\n",
    "                x_last = target.view(len(target), 1, -1)\n",
    "            else:\n",
    "                x_last = t_pred\n",
    "            hn1 = hn2\n",
    "            cn1 = cn2\n",
    "\n",
    "        # Concatenate the predictions and return\n",
    "        return torch.cat(pred, dim=1), loss\n",
    "\n",
    "    def predict(self, X, dim_pred= 1):\n",
    "\n",
    "        # Copy data\n",
    "        x = X\n",
    "        # Last position traj\n",
    "        x_last = X[:,-1,:].view(len(x), 1, -1) \n",
    "\n",
    "        # Layers\n",
    "        emb = self.embedding(X) # encoder for batch\n",
    "        lstm_out, (hn1, cn1) = self.lstm1(emb.permute(1,0,2)) # LSTM for batch [seq_len, batch, input_size] \n",
    "\n",
    "        loss = 0\n",
    "        pred = []\n",
    "        for i in range(dim_pred):\n",
    "            emb_last = self.embedding(x_last) # encoder for last position\n",
    "            lstm_out, (hn2, cn2) = self.lstm2(emb_last.permute(1,0,2), (hn1,cn1)) # lstm for last position with hidden states from batch\n",
    "\n",
    "            # Decoder and Prediction\n",
    "            dec = self.decoder(hn2.permute(1,0,2))\n",
    "            t_pred = dec + x_last\n",
    "            pred.append(t_pred)\n",
    "\n",
    "            # Update the last position\n",
    "            x_last = t_pred\n",
    "            hn1 = hn2\n",
    "            cn1 = cn2\n",
    "\n",
    "        # Concatenate the predictions and return\n",
    "        return torch.cat(pred, dim=1).detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rho(sigma, delta):\n",
    "    \"\"\"\n",
    "    sigma is represented by softplus function  'sigma = log(1 + exp(rho))' to make sure it \n",
    "    remains always positive and non-transformed 'rho' gets updated during backprop.\n",
    "    \"\"\"\n",
    "    rho = torch.log(torch.expm1(delta * torch.abs(sigma)) + 1e-20)\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MOPED_layer(layer, det_layer, delta):\n",
    "    \"\"\"\n",
    "    Set the priors and initialize surrogate posteriors of Bayesian NN with Empirical Bayes\n",
    "    MOPED (Model Priors with Empirical Bayes using Deterministic DNN)\n",
    "    Reference:\n",
    "    [1] Ranganath Krishnan, Mahesh Subedar, Omesh Tickoo.\n",
    "        Specifying Weight Priors in Bayesian Deep Neural Networks with Empirical Bayes. AAAI 2020.\n",
    "    \"\"\"\n",
    "    if (str(layer) == 'Conv2dReparameterization()'):\n",
    "        #set the priors\n",
    "        print(str(layer))\n",
    "        layer.prior_weight_mu = det_layer.weight.data\n",
    "        if layer.prior_bias_mu is not None:\n",
    "            layer.prior_bias_mu = det_layer.bias.data\n",
    "\n",
    "        #initialize surrogate posteriors\n",
    "        layer.mu_kernel.data = det_layer.weight.data\n",
    "        layer.rho_kernel.data = get_rho(det_layer.weight.data, delta)\n",
    "        if layer.mu_bias is not None:\n",
    "            layer.mu_bias.data = det_layer.bias.data\n",
    "            layer.rho_bias.data = get_rho(det_layer.bias.data, delta)\n",
    "\n",
    "    elif (isinstance(layer, nn.Conv2d)):\n",
    "        print(str(layer))\n",
    "        layer.weight.data = det_layer.weight.data\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data = det_layer.bias.data2\n",
    "\n",
    "    elif (str(layer) == 'LinearReparameterization()'):\n",
    "        print(str(layer))\n",
    "        layer.prior_weight_mu = det_layer.weight.data\n",
    "        if layer.prior_bias_mu is not None:\n",
    "            layer.prior_bias_mu = det_layer.bias.data\n",
    "\n",
    "        #initialize the surrogate posteriors\n",
    "\n",
    "        layer.mu_weight.data = det_layer.weight.data\n",
    "        layer.rho_weight.data = get_rho(det_layer.weight.data, delta)\n",
    "        if layer.mu_bias is not None:\n",
    "            layer.mu_bias.data = det_layer.bias.data\n",
    "            layer.rho_bias.data = get_rho(det_layer.bias.data, delta)\n",
    "\n",
    "    elif str(layer).startswith('Batch'):\n",
    "        #initialize parameters\n",
    "        print(str(layer))\n",
    "        layer.weight.data = det_layer.weight.data\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data = det_layer.bias.data\n",
    "        layer.running_mean.data = det_layer.running_mean.data\n",
    "        layer.running_var.data = det_layer.running_var.data\n",
    "        layer.num_batches_tracked.data = det_layer.num_batches_tracked.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 126,
     "status": "ok",
     "timestamp": 1626217128372,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "-2DsuYRjGrvw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lstm_encdec_variational(\n",
       "  (embedding): LinearReparameterization()\n",
       "  (lstm1): LSTMReparameterization(\n",
       "    (ih): LinearReparameterization()\n",
       "    (hh): LinearReparameterization()\n",
       "  )\n",
       "  (lstm2): LSTMReparameterization(\n",
       "    (ih): LinearReparameterization()\n",
       "    (hh): LinearReparameterization()\n",
       "  )\n",
       "  (decoder): LinearReparameterization()\n",
       "  (loss_fun): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Variational\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = lstm_encdec_variational(2,128,256,2,prior_mu,prior_sigma,posterior_mu_init,posterior_rho_init)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../training_checkpoints/model_deterministic5.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c6ed9d73c0db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Cargamos el Modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../training_checkpoints/model_deterministic5.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../training_checkpoints/model_deterministic5.pth'"
     ]
    }
   ],
   "source": [
    "# Model Deterministic\n",
    "#det_model = torch.nn.DataParallel(det_resnet.__dict__[args.arch](pretrained=True))\n",
    "det_model = LSTM_determinista(2,128,256,2)\n",
    "\n",
    "# Cargamos el Modelo\n",
    "det_model.load_state_dict(torch.load(\"../training_checkpoints/model_deterministic5.pth\"))\n",
    "det_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOPED enabled\n",
      "LinearReparameterization()\n",
      "LinearReparameterization()\n"
     ]
    }
   ],
   "source": [
    "delta = 0.2\n",
    "\n",
    "print(\"MOPED enabled\")\n",
    "for (idx_1, layer_1), (det_idx_1, det_layer_1) in zip( enumerate(model.children()), enumerate(det_model.children())):\n",
    "    MOPED_layer(layer_1, det_layer_1, delta)\n",
    "    for (idx_2, layer_2), (det_idx_2, det_layer_2) in zip( enumerate(layer_1.children()), enumerate(det_layer_1.children())):\n",
    "        MOPED_layer(layer_2, det_layer_2, delta)\n",
    "\n",
    "        for (idx_3, layer_3), (det_idx_3, det_layer_3) in zip( enumerate(layer_2.children()), enumerate(det_layer_2.children())):\n",
    "            MOPED_layer(layer_3, det_layer_3, delta)\n",
    "            for (idx_4, layer_4), (det_idx_4, det_layer_4) in zip( enumerate(layer_3.children()), enumerate(det_layer_3.children())):\n",
    "                MOPED_layer(layer_4, det_layer_4, delta)\n",
    "                for (idx_5, layer_5), (det_idx_5, det_layer_5) in zip( enumerate(layer_4.children()), enumerate(det_layer_4.children())):\n",
    "                    MOPED_layer(layer_5, det_layer_5, delta)\n",
    "                    for (idx_6, layer_6), (det_idx_6, det_layer_6) in zip( enumerate(layer_5.children()), enumerate(det_layer_5.children())):\n",
    "                        MOPED_layer(layer_6, det_layer_6, delta)\n",
    "model.state_dict()\n",
    "del det_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 903961,
     "status": "ok",
     "timestamp": 1626218033804,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "2g_bvInYjAJZ",
    "outputId": "d83ede94-42e2-4494-fd21-3f30485d61ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- \n",
      "epoch:  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-66b6233fdfc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Step 2. Run our forward pass and compute the losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnl_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mnl_loss_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnl_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/repositories/devel/trajpred-bdl/tests/../models/lstm_encdec_variational.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, y, training, num_mc)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mkl_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# Layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# encoder for batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mkl_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/repositories/devel/trajpred-bdl/tests/../bayesian-torch/bayesian_torch/layers/variational_layers/linear_variational.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0msigma_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_weight\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0msigma_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         kl_weight = self.kl_div(self.mu_weight, sigma_weight,\n\u001b[1;32m    132\u001b[0m                                 self.prior_weight_mu, self.prior_weight_sigma)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Training the Model\n",
    "optimizer = optim.SGD(model.parameters(), lr=initial_lr)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.015)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.03)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.08) #nan\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.07) #nan \n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.06) #nan \n",
    "\n",
    "num_mc = 10\n",
    "\n",
    "nl_loss_ = []\n",
    "kl_loss_ = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    print(\"----- \")\n",
    "    print(\"epoch: \", epoch)\n",
    "    error = 0\n",
    "    total = 0\n",
    "    M     = len(batched_train_data)\n",
    "    for batch_idx, (data, target, _a , _b) in enumerate(batched_train_data):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            data  = data.to(device)\n",
    "            target=target.to(device)\n",
    "\n",
    "        # Step 2. Run our forward pass and compute the losses\n",
    "        pred, nl_loss, kl_loss = model(data, target, training=True, num_mc=num_mc)\n",
    "        \n",
    "        nl_loss_.append(nl_loss.detach().item())\n",
    "        kl_loss_.append(kl_loss.detach().item())\n",
    "        \n",
    "        # TODO: Divide by the batch size\n",
    "        #pi     = (2.0**(M-batch_idx))/(2.0**M-1) #  Blundell?\n",
    "        loss   = nl_loss+ kl_loss\n",
    "        error += loss.detach().item()\n",
    "        total += len(target)\n",
    "\n",
    "        # Step 3. Compute the gradients, and update the parameters by\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Average training loss: {:.3e}\".format(error/total))\n",
    "\n",
    "    # Validation\n",
    "    error = 0\n",
    "    total = 0\n",
    "    M     = len(batched_val_data)\n",
    "    for batch_idx, (data_val, target_val, _ , _) in enumerate(batched_val_data):\n",
    "        if torch.cuda.is_available():\n",
    "            data_val  = data_val.to(device)\n",
    "            target_val=target_val.to(device)\n",
    "        pred_val, nl_loss, kl_loss = model(data_val, target_val)\n",
    "        pi     = (2.0**(M-batch_idx))/(2.0**M-1) # From Blundell\n",
    "        loss   = nl_loss+ pi*kl_loss\n",
    "        error += loss.detach().item()\n",
    "        total += len(target_val)\n",
    "\n",
    "    print(\"Average validation loss: {:.3e}\".format(error/total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99A6ayLglGmV"
   },
   "outputs": [],
   "source": [
    "plt.plot(nl_loss_,\"--b\", label=\"nl_loss\")\n",
    "plt.plot(kl_loss_,\"--r\", label=\"kl_loss\")\n",
    "plt.title(\"Loss training\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nl_loss_,\"--b\", label=\"nl_loss\")\n",
    "plt.title(\"Loss training\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kl_loss_,\"--r\", label=\"kl_loss\")\n",
    "plt.title(\"Loss training\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el Modelo\n",
    "torch.save(model.state_dict(), \"../training_checkpoints/model_MOPED.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1626218044464,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "LtBmwWGBHV4b"
   },
   "outputs": [],
   "source": [
    "def plot_traj(pred_traj, obs_traj_gt, pred_traj_gt, test_homography, background):\n",
    "    print(\"-----\")\n",
    "    homography = np.linalg.inv(test_homography)\n",
    "\n",
    "    # Convert it to absolute (starting from the last observed position)\n",
    "    displacement = np.cumsum(pred_traj, axis=0)\n",
    "    this_pred_out_abs = displacement + np.array([obs_traj_gt[-1].numpy()])\n",
    "\n",
    "    obs   = image_to_world_xy(obs_traj_gt, homography, flip=False)\n",
    "    gt    = image_to_world_xy(pred_traj_gt, homography, flip=False)\n",
    "    gt = np.concatenate([obs[-1,:].reshape((1,2)), gt],axis=0)\n",
    "    tpred   = image_to_world_xy(this_pred_out_abs, homography, flip=False)\n",
    "    tpred = np.concatenate([obs[-1,:].reshape((1,2)), tpred],axis=0)\n",
    "\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(background)\n",
    "    plt.plot(obs[:,0],obs[:,1],\"-b\", linewidth=2, label=\"Observations\")\n",
    "    plt.plot(gt[:,0], gt[:,1],\"-r\", linewidth=2, label=\"Ground truth\")\n",
    "    plt.plot(tpred[:,0],tpred[:,1],\"-g\", linewidth=2, label=\"Prediction\")\n",
    "    plt.legend()\n",
    "    plt.title('Trajectory samples')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1HCeVlXQLYZVwBDinWWjWtxv6QEqFgd2u"
    },
    "executionInfo": {
     "elapsed": 61967,
     "status": "ok",
     "timestamp": 1626218110872,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "30joaw2kMWDY",
    "outputId": "4c9ae6b1-9a48-4b16-a59b-612ab8fd3024"
   },
   "outputs": [],
   "source": [
    "from obstacles import image_to_world_xy\n",
    "\n",
    "num_samples = 30\n",
    "num_monte_carlo = 20\n",
    "i = 1 # sample of batch\n",
    "bck = np.load('background.npy')\n",
    "\n",
    "# Testing\n",
    "cont = 0\n",
    "for batch_idx, (datarel_test, targetrel_test, data_test, target_test) in enumerate(batched_test_data):\n",
    "    print(\"-----\")\n",
    "    print(cont)\n",
    "    if torch.cuda.is_available():\n",
    "        datarel_test  = datarel_test.to(device)\n",
    "        targetrel_test= targetrel_test.to(device)\n",
    "        data_test     = data_test.to(device)\n",
    "        target_test   = target_test.to(device)        \n",
    "    homography = np.linalg.inv(test_homography)\n",
    "    \n",
    "    obs_traj_gt  = data_test[i,:,:]\n",
    "    pred_traj_gt = target_test[i,:,:]\n",
    "    obs   = image_to_world_xy(obs_traj_gt.cpu(), homography, flip=False)\n",
    "    gt    = image_to_world_xy(pred_traj_gt.cpu(), homography, flip=False)\n",
    "    gt = np.concatenate([obs[-1,:].reshape((1,2)), gt], axis=0)\n",
    "\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(bck)\n",
    "    plt.plot(obs[:,0],obs[:,1],\"-b\", linewidth=2, label=\"Observations\")\n",
    "    plt.plot(gt[:,0], gt[:,1],\"-r\", linewidth=2, label=\"Ground truth\")\n",
    "\n",
    "    # prediction\n",
    "    for mc_run in range(num_monte_carlo):\n",
    "        pred, kl = model.predict(datarel_test, dim_pred=12)\n",
    "        # ploting \n",
    "        #plot_traj(pred[i,:,:], data_test[i,:,:], target_test[i,:,:], test_homography, bck)\n",
    "\n",
    "        pred_traj = pred[i,:,:]\n",
    "\n",
    "        # Convert it to absolute (starting from the last observed position)\n",
    "        displacement      = np.cumsum(pred_traj, axis=0)\n",
    "        this_pred_out_abs = displacement + np.array([obs_traj_gt[-1].cpu().numpy()])\n",
    "\n",
    "        tpred = image_to_world_xy(this_pred_out_abs, homography, flip=False)\n",
    "        tpred = np.concatenate([obs[-1,:].reshape((1,2)), tpred], axis=0)\n",
    "\n",
    "        if mc_run == 0:\n",
    "            plt.plot(tpred[:,0],tpred[:,1],\"-g\", linewidth=2, label=\"Prediction\")\n",
    "        else:\n",
    "            plt.plot(tpred[:,0],tpred[:,1],\"-g\", linewidth=2)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('Trajectory samples')\n",
    "    plt.savefig(\"traj_variational_1_4\"+str(cont)+\".pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    cont += 1\n",
    "        \n",
    "    if cont == num_samples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpU2HvaQKObj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRpI157sKOeG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n38rE4UKKOhC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Prueba_con_torch_variacional.ipynb",
   "provenance": [
    {
     "file_id": "19NEdCOFkz192E98RYrt3dC_jtWhqp8BR",
     "timestamp": 1612389852697
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
